{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import xlwings as xw\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "def get_source(account):\n",
    "    electronics = [\n",
    "        \"OH_EZPASS_\", \"HCTRA_\", \"NY_EZPASS_\", \"EXPRESS_TOLL_20459648\", 'ICD', 'NTTA_',\n",
    "        \"PA_EZPASS_\", \"EXPRESS_TOLL_13169610\", \"NJ_EZPASS_\", \"FASTRAK_\", \"SUNPASS_\",\n",
    "        \"THE_TOLL_ROADS_\", \"GOOD_TO_GO_\", \"IPASS_\", \"TX_TAG_\", \"SOUTHERN_CONNECTOR_\",\n",
    "        \"INDIANA_TOLL_ROADS_\", \"EXPRESS_TOLL_12871286\", \"RIVERLINK\", \"ELECTRONIC TOLLS\"\n",
    "    ]\n",
    "    \n",
    "    if account is None:\n",
    "        return \"MAIL TOLL\"\n",
    "    \n",
    "    account_upper = account.upper()\n",
    "    for source in electronics:\n",
    "        if source in account_upper:\n",
    "            return \"ELECTRONIC\"\n",
    "    \n",
    "    if \"CITATION\" in account_upper:\n",
    "        return \"CITATION\"\n",
    "    \n",
    "    return \"MAIL TOLL\"\n",
    "\n",
    "source_dir = r'C:/Users/BelindaNamwenge/Documents/Projects/OCR_PROCESSING/scripts'\n",
    "source_path = Path(source_dir)\n",
    "\n",
    "excel_files = [file for file in source_path.glob('*.xlsx') if not file.name.startswith('~$')]\n",
    "\n",
    "if not excel_files:\n",
    "    print(\"No Excel files found.\")\n",
    "    exit()\n",
    "\n",
    "# Create a new workbook\n",
    "combined_wb = xw.Book()\n",
    "sheet_counter = 0\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "for excel_file in excel_files:\n",
    "    try:\n",
    "        wb = xw.Book(excel_file)\n",
    "        for sheet in wb.sheets:\n",
    "            try:\n",
    "                data_range = sheet.range('A1').expand().value\n",
    "                df = pd.DataFrame(data_range[1:], columns=data_range[0])\n",
    "                file_name = excel_file.name\n",
    "\n",
    "                week_match = re.search(r'\\w+\\s+(\\d+)', file_name)\n",
    "                year_match = re.search(r'\\((\\d{4})\\)', file_name)\n",
    "                report_type_match = re.search(r'(AFP|DSP-MMBT|TRAILERS|TOM)', file_name, re.IGNORECASE)\n",
    "                week = week_match.group(1) if week_match else \"\"\n",
    "                year = year_match.group(1) if year_match else \"\"\n",
    "                report_type = report_type_match.group(1).upper() if report_type_match else \"\"\n",
    "\n",
    "                df[\"FileName\"] = file_name\n",
    "                df[\"WEEK\"] = week\n",
    "                df[\"YEAR\"] = year\n",
    "                df[\"REPORT TYPE\"] = report_type\n",
    "\n",
    "                if \"TXN PROCESSING DATE\" not in df.columns:\n",
    "                    df[\"TXN PROCESSING DATE\"] = list(map(lambda x, y: datetime.datetime.strptime(f'{y}-W{x}-1', \"%Y-W%W-%w\") + datetime.timedelta(days=4), df[\"WEEK\"], df[\"YEAR\"]))\n",
    "                if \"SLA Start Date\" not in df.columns:\n",
    "                    df[\"SLA Start Date\"] = df[\"TXN PROCESSING DATE\"].apply(lambda x: x - datetime.timedelta(days=60))\n",
    "                if \"TXN TIME DIFF\" not in df.columns:\n",
    "                    df[\"TXN TIME DIFF\"] = list(map(lambda x, y: (x - y).days, df[\"TXN PROCESSING DATE\"], df[\"EXIT DATE/TIME\"]))\n",
    "                if ('SOURCE' in df.columns) and not (\"ACCOUNT\" in df.columns):\n",
    "                    account_check = df[df[\"SOURCE\"].isna()]\n",
    "                    for index, row in account_check.iterrows():\n",
    "                        df.loc[index, \"SOURCE\"] = row[\"ACCOUNT\"]\n",
    "\n",
    "                # Add TRANSACTION TYPE logic\n",
    "                if \"TRANSACTION TYPE\" not in df.columns:\n",
    "                    df[\"TRANSACTION TYPE\"] = None\n",
    "\n",
    "                if all(col in df.columns for col in [\"HIGH RATES\", \"AMOUNT\", \"TRANSPONDER\"]):\n",
    "                    df.loc[df[\"HIGH RATES\"] > df[\"AMOUNT\"], \"TRANSACTION TYPE\"] = \"Transponder Toll\"\n",
    "                    df.loc[df[\"AMOUNT\"] > df[\"HIGH RATES\"], \"TRANSACTION TYPE\"] = \"Plate Toll\"\n",
    "\n",
    "                    pattern = re.compile(r'[^a-zA-Z0-9]')\n",
    "                    transponder_null = df[\"TRANSPONDER\"].apply(lambda x: True if pattern.search(str(x)) or x == \"null\" or x == \"-\" else False)\n",
    "\n",
    "                    condition = df[\"AMOUNT\"] == df[\"HIGH RATES\"]\n",
    "                    df.loc[condition & transponder_null, \"TRANSACTION TYPE\"] = \"Plate Toll\"\n",
    "                    df.loc[condition & ~transponder_null, \"TRANSACTION TYPE\"] = \"Transponder Toll\"\n",
    "\n",
    "                df[\"SOURCE\"] = df[\"ACCOUNT\"].apply(get_source)\n",
    "                df[\"SLA MET\"] = df[\"TXN TIME DIFF\"].apply(lambda x: \"Within SLA\" if x <= 60 else \"Outside SLA\")\n",
    "\n",
    "                merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process sheet {sheet.name} in {excel_file}: {e}\")\n",
    "        wb.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to open workbook {excel_file}: {e}\")\n",
    "\n",
    "merged_df[\"TXN TIME DIFF\"] = list(map(lambda x, y: (x - y).days, merged_df[\"TXN PROCESSING DATE\"], merged_df[\"EXIT DATE/TIME\"]))\n",
    "\n",
    "# Write the combined data to the sheet in chunks\n",
    "try:\n",
    "    while True:\n",
    "        sheet_counter += 1\n",
    "        sheet_name = f'Combined Data {sheet_counter}'\n",
    "        try:\n",
    "            if sheet_counter > 1:\n",
    "                combined_sheet = combined_wb.sheets.add(sheet_name)\n",
    "            else:\n",
    "                combined_sheet = combined_wb.sheets['Combined Data']\n",
    "\n",
    "            chunk_size = 100000  # Adjusted chunk size for memory management\n",
    "            start_row = 1 if sheet_counter == 1 else 2  # Start at 2 for subsequent sheets\n",
    "\n",
    "            # Write column headers if it's the first sheet\n",
    "            if sheet_counter == 1:\n",
    "                combined_sheet.range('A1').value = merged_df.columns.tolist()\n",
    "\n",
    "            # Calculate the number of rows to write\n",
    "            end_row = start_row + chunk_size - 1\n",
    "            rows_to_write = merged_df.iloc[start_row - 1:end_row]\n",
    "\n",
    "            if rows_to_write.empty:\n",
    "                break\n",
    "\n",
    "            try:\n",
    "                # Write data in chunks\n",
    "                combined_sheet.range(f'A{start_row}').value = rows_to_write.values.tolist()\n",
    "                start_row += chunk_size\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to write data to sheet {sheet_name}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to create or access sheet {sheet_name}: {e}\")\n",
    "\n",
    "    combined_wb.save('all_sheets.xlsx')\n",
    "\n",
    "    if len(combined_wb.app.books) == 1:\n",
    "        combined_wb.app.quit()\n",
    "    else:\n",
    "        combined_wb.close()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
